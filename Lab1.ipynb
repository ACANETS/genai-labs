{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfsDR_omdNea"
   },
   "source": [
    "# Lab 1 - EECE.4860/5860 at UMass Lowell - Spring 2025\n",
    "\n",
    "This lab requires you to practice with LLMs on Intel Tiber AI cloud, such as how to load LLM models by utilizing Hugging Face, change model settings, make queries, and generate required outputs through prompt engineering. Students in EECE.5860 will practice how to finetune an LLM using a new dataset.\n",
    "\n",
    "## **Note** This lab has three parts. Part 1 and Part 2 are for all the students. Part 3 contains additional requirements for EECE.5860 students. EECE.4860 students do not need to complete Part 3.\n",
    "\n",
    "\n",
    "## Part 1:   Simple LLM Inference (10 points)\n",
    "\n",
    "Execute the [Simple LLM Inference](simple_llm_inference.ipynb) to experiment with different models and their settings (e.g. temperature). Record the differences in their outputs when given the same input prompt. Evaluate the quality of their completions using your own words. (10 points)\n",
    "\n",
    "## Part 2: Prompt Engineering (10 points)\n",
    "\n",
    "Use **gemma-2-2b-it** model and one prompt to generate the list of winners and years of the World Series Championships from 2010 to **2025**. Your prompt and completion will be graded using the following rubrics (out of total 10 points):\n",
    "\n",
    "* the output should include a list of winners and years in json format. (6 points)\n",
    "* the json output must include the year of 2024 (2 points)\n",
    "* the output need to discuss/explain the information about the year of 2025 (2 points)\n",
    "\n",
    "## Part 3: Model Fine Tuning (10 points)\n",
    "\n",
    "Building on the example notebook “gemma_xpu_finetuning.ipynb”, you will use a new dataset to finetune the gemma-2b model. Your notebook will be graded as follows:\n",
    "\n",
    "* You first sample a few questions from the dataset as prompts to assess the quality of the completions from the original gemma-2b model. (3 points)\n",
    "* Then you will use this dataset to finetune the **gemma-2b** model and save it as a new model called **gemma-2b-finetuned**. (4 points)\n",
    "* Assess the finetuned model using the same test prompts. (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Submission\n",
    "\n",
    "Please use screenshots to document the outputs from your notebooks. Include the screenshots in your lab report, which is due by the posted due dates."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Gemma_Basics_with_HF.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "PyTorch GPU",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
