{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Lab 3 Part 2 - EECE.4860/5860 at UMass Lowell\n",
    "\n",
    "Complete the missing code to create a new tool based on RAG, and execute a complex query that invokes the tools.\n",
    "\n",
    "This example uses LangGraph APIs.\n",
    "\n",
    "We will use ChatNVIDIA model because it supports local mode when working with LangGraph. You need to apply for a free API key via https://build.nvidia.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "%pip install --upgrade langchain langgraph langchain-community langchain-huggingface langchain-nvidia-ai-endpoints wikipedia numexpr pypdf sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def magic_function(input: int) -> int:\n",
    "    \"\"\"Applies a magic function to an input.\"\"\"\n",
    "    return input + 2\n",
    "\n",
    "tools = [magic_function]\n",
    "\n",
    "query = \"what is the value of magic_function(3)?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "top_k = 1\n",
    "max_tokens = 512\n",
    "chunk_size=1000\n",
    "overlap=50\n",
    "\n",
    "# The new tool you need to create is a RAG tool that answer queries about DeepSeek-R1\n",
    "# The tool leverages a few APIs that you see in the simple_rag.ipynb example, including\n",
    "# RecursiveCharacterTextSplitter(), VectorstoreIndexCreator(), vectorstore.similarity_search()\n",
    "#\n",
    "loader = PyPDFLoader(\"https://arxiv.org/pdf/2501.12948.pdf\")\n",
    "docs = loader.load()\n",
    "# TODO: call  RecursiveCharacterTextSplitter() using chunk_size and overlap\n",
    "# text_splitter = ...\n",
    "\n",
    "# TODO: split the docuement using text_splitter and docs\n",
    "# splits = ...\n",
    "\n",
    "# TODO: create the vector database by calling VectorstoreIndexCreator()\n",
    "# TODO: using HuggingFaceEmbedding() and \"intfloat/multilingual-e5-large-instruct\" model\n",
    "#index = VectorstoreIndexCreator(\n",
    "#    embedding= ...,\n",
    "#    text_splitter=...\n",
    "#).from_loaders([loader])\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_deepseek_r1_paper(input: Annotated[str, \"Query relating to DeepSeek-R1\"]) -> str:\n",
    "    \"\"\"Provides context that can be used to answer questions on DeepSeek-R1\"\"\"\n",
    "    \n",
    "    print(f\"Received input query: {input}\\n\")\n",
    "\n",
    "    # TODO: perform similarity search on the input and top_k\n",
    "    # results = ...\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No results found for the query.\\n\\n\")\n",
    "        return \"no results\"\n",
    "    \n",
    "    # TODO: concatenate the results using \"\\n\" as a separator\n",
    "    # context = \n",
    "\n",
    "    if context:\n",
    "        print(f\"Context found:\\n{context}\\n\\n\")\n",
    "        \n",
    "    return context\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use ChatNVIDIA model because it supports local mode when working with LangGraph.\n",
    "#You need to apply for a free API key via https://build.nvidia.com\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "if not os.getenv(\"NVIDIA_API_KEY\"):\n",
    "    # Note: the API key should start with \"nvapi-\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "#print(ChatNVIDIA.get_available_models())\n",
    "# not all the models in ChatNVIDIA supports tools.\n",
    "tool_models = [\n",
    "    model for model in ChatNVIDIA.get_available_models() if model.supports_tools\n",
    "]\n",
    "print(tool_models)\n",
    "\n",
    "llm_nvidia = ChatNVIDIA(model=\"meta/llama-3.1-405b-instruct\",\n",
    "                           temperature=0.1,\n",
    "                            max_tokens=512,\n",
    "                            top_p=1.0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMMathChain, LLMChain\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "wikipedia_wrapper = WikipediaAPIWrapper()\n",
    "wikipedia_tool = Tool(\n",
    "    name=\"Wikipedia\",\n",
    "    func=wikipedia_wrapper.run,\n",
    "    description=\"A tool for searching the Internet to find various information on the topics mentioned.\"\n",
    ")\n",
    "math_chain = LLMMathChain.from_llm(llm=llm_nvidia, verbose=True)\n",
    "calculator = Tool.from_function(\n",
    "    name=\"Calculator\",\n",
    "    func=math_chain.run,\n",
    "    description=\"A tool for solving mathematical problems. Provide only the mathematical expressions.\"\n",
    ")\n",
    "\n",
    "tools=[wikipedia_tool, calculator, magic_function, query_deepseek_r1_paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "langgraph_agent_executor = create_react_agent(llm_nvidia, tools)\n",
    "\n",
    "# Increase the recursion limit in the configuration\n",
    "config = {\n",
    "   \"recursion_limit\": 20  # Increase the limit as needed\n",
    "}\n",
    "\n",
    "query1 = \"In what year was the film Departed with Leopnardo Dicaprio released? What is this year raised to the power of 0.43?\"\n",
    "\n",
    "query2 = \"Use the year the film Departed with Leopnardo Dicaprio was released to calculate the value of magic_function.\"\n",
    "\n",
    "query3 = \"What are the main limitations of DeepSeek-R1?\"\n",
    "\n",
    "messages1 = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query1)]}, config=config)\n",
    "\n",
    "print('-'*200)\n",
    "print(\"Query 1:\", query1)\n",
    "print('-'*200)\n",
    "print(\"Response 1:\", messages1[\"messages\"][-1].content)\n",
    "print('-'*200, '\\n')\n",
    "\n",
    "messages2 = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query2)]}, config=config)\n",
    "print('-'*200)\n",
    "print(\"Query 2:\", query2)\n",
    "print('-'*200)\n",
    "print(\"Response 2:\", messages2[\"messages\"][-1].content)\n",
    "print('-'*200, '\\n')\n",
    "\n",
    "\n",
    "messages3 = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query3)]}, config=config)\n",
    "print('-'*200)\n",
    "print(\"Query 3:\", query3)\n",
    "print('-'*200)\n",
    "print(\"Response 3:\", messages3[\"messages\"][-1].content)\n",
    "print('-'*200, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.6",
   "language": "python",
   "name": "pytorch-2.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
